---
layout: post
title:  "Normalization Layers are All SAM Needs"
date:   2023-09-26 09:42:09 +0100
categories: jekyll update
---

Various works have explored the potential connection between flatness of minima and generalization performance of neural networks (e.g. Hochreiter and Schmidhuber, 1997, Keskar et al., 2017, Chaudhari et al., 2017), despite critiques that "sharper minima can generalize better" (Dinh et al., 2017, Andriushchenko et al., 2023). The sharpness-aware minimization (SAM) technique by Foret et al., 2021 actively aims to find minima with low sharpness and was found to be remarkably effective in enhancing generalization performance in various settings (e.g. Bahri et al., 2022, Chen et al., 2022).

In our work we show that perturbing only the normalization layers (SAM-OnlyNorm) outperforms perturbing all parameters (SAM). This is illustrated for a WideResNet-28 on CIFAR-100 data in the figure below. Further, we observe that training with SAM-ON can in fact increase sharpness, casting doubt on whether SAM's enhanced generalization performance is caused solely by reduced sharpness. 

If this sparked your interest, check out the full paper: [arXiv:2306.04226](https://arxiv.org/abs/2306.04226) (which includes a link to the code) and don't hesitate to get in touch with any questions. <br>
This paper is joint work with Max MÃ¼ller, David Rolnick, and Matthias Hein and has been accepted to NeurIPS 2023. 

<img src="/pics/SAMON.png" width="800"/>




