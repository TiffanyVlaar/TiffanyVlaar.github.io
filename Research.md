---
layout: page
title: Research
permalink: /research/
---

Research Interests: Mathematics for Deep Learning, Sampling Methods, Numerical methods for Stochastic Differential Equations, Understanding Deep Learning, and Physics-informed Machine Learning.

Papers: <br>
[Multirate Training of Neural Networks [blog]]({{TiffanyVlaar.github.io}}/jekyll/update/2021/06/07/Multirate), *ICML 2022*. arXiv:2106.10771

[What can linear interpolation of neural network loss landscapes tell us? [blog]]({{TiffanyVlaar.github.io}}/jekyll/update/2021/06/02/LinearInterpolation), *ICML 2022*. arXiv:2106.16004

[Better Training using Weight-Constrained Stochastic Dynamics [blog]]({{TiffanyVlaar.github.io}}/jekyll/update/2020/11/04/ConstraintBasedReg), *ICML 2021*. <br>
In this paper we use constrained stochastic differential equations to train deep neural networks. We provide a general framework with accompanying discretization schemes and a statistical guarantee on the convergence of the
training. This general framework enables the implementation of powerful new constraints, such as orthogonality of the weight matrix. <br>
Related workshop paper [Constraint-based Regularization of Neural Networks](https://arxiv.org/abs/2006.10114) *was accepted as spotlight presentation for NeurIPS 2020 Optimization for ML workshop and received the best student paper award.* Presentation: [YouTube link](https://youtu.be/5xhvuNPmCj4) <br>

[Partitioned Integrators for Thermodynamic Parameterization of Neural Networks]({{TiffanyVlaar.github.io}}/jekyll/update/2019/08/31/NewPaper.html)*, Foundations of Data Science 1 (4) , 457-489 (2019). Accepted as digital acceptance to NeurIPS 2019 Machine Learning and the Physical Sciences workshop.* <br>
This thermodynamic parameterization technique for neural network training allows for enhanced exploration of problems with complicated loss landscapes, which are thought to arise in molecular dynamics applications.

<!---Check out my new blogpost about the paper [here]({{TiffanyVlaar.github.io}}/jekyll/update/2019/08/31/NewPaper.html)-->



Other Research Projects:
- Gerrymandering in the United Kingdom: Interpreting political geography in a statistical physics framework and using Markov Chain Monte Carlo methods for Assessing the Fairness of Political Constituencies. Related blogpost: [Gerrymandering blog]({{TiffanyVlaar.github.io}}/jekyll/update/2019/11/18/Gerrymandering.html)
- Introducing sparsity in neural networks using sampling. <br>
  Some related posts: [Generalization Error]({{TiffanyVlaar.github.io}}/jekyll/update/2019/03/27/Generalization.html), [Sparsity in Neural Networks]({{TiffanyVlaar.github.io}}/jekyll/update/2019/05/10/Sparsity.html), [Loss Landscape]({{TiffanyVlaar.github.io}}/jekyll/update/2019/07/20/LossLandscape.html).
 - Limitations of using test accuracy as the sole metric for model evaluation by examining neural network behavior at the classification boundary. Poster accepted for NeurIPS 2021 I (Still) Can’t Believe It’s Not Better (ICBINB) workshop. Preprint available on request. <br>
- Applying Bayesian inference techniques to stochastic models (in particular Langevin dynamics models) for flocking
- Stochastic Multiple Timestepping techniques for coupled systems of fast and slow variables

Selected Workshops and Summerschools: 
<!--- Poster at Machine Learning and Dynamical Systems symposium, Fields Institute, 2022.-->
- Two spotlight talks and posters at ICML, 2022.
- Poster at "Connections between interacting particle dynamics and data science" ICMS workshop, 2022.
- Talk at "ODE and SDE methods in machine learning" symposium, NUMDIFF-16, 2021.
- Poster at Theory of Deep Learning workshop, Newton Institute, Cambridge, 2021.
- Talk and poster presenter at ICML 2021.
- Spotlight presentation at NeurIPS 2020 Optimization for ML workshop, December 2020.
- Statistical Physics & Machine Learning summer school, Les Houches, July 2020.
- Machine Learning Summer School (MLSS), Tuebingen, June 2020.
- Invited talk at Structural Inference in High Dimensional models, Mathematics of Learning conference, Bordeaux, 2020. Cancelled due to pandemic.
<!-- Poster at Foundations of Computational Mathematics, 2020. Cancelled due to pandemic.-->
- Research Collaboration Visit to visit Gabriel Stoltz (CERMICS, Ecole des Ponts ParisTech), March 2020. Cancelled due to pandemic.
- Molecular Simulation and Machine Learning conference, Temple University, Rome, January 2020.
- Sampling algorithms on manifolds workshop, Isaac Newton Institute, Cambridge, November 2019.
- Invited Poster presentation at Amazon Research Days, Edinburgh, November 2019.
- Research Collaboration Visit at Courant Institute, NYU hosted by Jonathan Weare. Engaging discussions with Joan Bruna, Stanislaw Jastrzebski, Mark Tuckerman, Eric Vanden-Eijnden, and Jonathan Weare, October 2019.
- Talk at Alan Turing’s UK-Japan robotics and AI research collaboration workshop, September 2019.
- Gene Golub SIAM summerschool on High-Performance Data Analytics, June 2019.
- CECAM - Computational mathematics for model reduction and predictive modelling in molecular and complex systems, May 2019.
- ICMS - Modelling Camp, May 2019.
- MIGSAA Advanced PhD Course - Diffusion Processes, Autumn 2018.
- Poster presentation at CSide Conference, University of Glasgow, November 2018.
<!--- i-like Workshop, Newcastle University, June 2018.-->
- Masterclass Professor David Dunson (Duke University) on Scalable Bayesian Inference, June 2018.
- Alan Turing Institute - Data-driven modelling of complex systems, May 2018.





