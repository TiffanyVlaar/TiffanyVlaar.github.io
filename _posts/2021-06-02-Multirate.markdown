---
layout: post
title:  "Multirate Training of Neural Networks"
date:   2021-06-02 01:42:09 +0100
categories: jekyll update
---

In this work we propose multirate training of neural networks: partitioning neural network parameters into "fast" and "slow" parts which are trained simultaneously using different learning rates.

<!---***Latent multiple time scales in deep learning *** <br>-->

This paper is joint work with Ben Leimkuhler. 
[arXiv preprint:2106.10771](https://arxiv.org/abs/2106.10771)

[Slides]({{TiffanyVlaar.github.io}}/slides/Multirate_Numdiff.pdf) for my talk at the "ODE and SDE methods in machine learning" symposium, NUMDIFF-16, 2021.

